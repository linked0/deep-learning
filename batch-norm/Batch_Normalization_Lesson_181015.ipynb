{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch_Normalization_Lesson_181015.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linked0/deep-learning/blob/master/batch-norm/Batch_Normalization_Lesson_181015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VBhtZtCVSd6r",
        "outputId": "eb6881a5-f7f8-45c8-9d55-6f72d4201940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q3psD_V9S__9",
        "outputId": "b9fa895d-f7ce-40a9-94eb-15e3a888f06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls sample_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y24eoYgHTG2D",
        "outputId": "15cb132e-f12b-4c02-ad35-774309cc0cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import MNIST data so we have something for out experiments\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-1e203c4f90fa>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fz4kdtRbZXPq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNet:\n",
        "  def __init__(self, initial_weights, activation_fn, use_batch_norm):\n",
        "    # Keep track of whether or not this network uses batch normalization.\n",
        "    self.use_batch_norm = use_batch_norm\n",
        "    self.name = 'With Batch Norm' if use_batch_norm else 'Without Batch Norm'\n",
        "    \n",
        "    # Batch normalization needs to do different calculations during training and inference,\n",
        "    # so we use this placeholder to tell the graph which behavior to use.\n",
        "    self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
        "    \n",
        "    self.training_accuracies = []\n",
        "    \n",
        "    self.build_network(initial_weights, activation_fn)\n",
        "    \n",
        "  def build_network(self, initial_weights, activation_fn):\n",
        "    self.input_layer = tf.placeholder(tf.float32, [None, initial_weights[0].shape[0]])\n",
        "    layer_in = self.input_layer\n",
        "    for weights in initial_weights[:-1]:\n",
        "      layer_in = self.fully_connected(layer_in, weights, activation_fn)\n",
        "    self.output_layer = self.fully_connected(layer_in, initial_weights[-1])\n",
        "  \n",
        "  def fully_connected(self, layer_in, initial_weights, activation_fn=None):\n",
        "    if self.use_batch_norm and activation_fn:\n",
        "      weights = tf.Variable(initial_weights)\n",
        "      linear_output = tf.matmul(layer_in, weights)\n",
        "      \n",
        "      batch_normalized_output = tf.layers.batch_normalization(linear_output, training=self.is_training)\n",
        "      \n",
        "      return activation_fn(batch_normalized_output)\n",
        "    \n",
        "    else:\n",
        "      weights = tf.Variable(initial_weights)\n",
        "      biases = tf.Variable(tf.zeros([initial_weights.shape[-1]]))\n",
        "      linear_output = tf.add(tf.matmul(layer_in, weights), biases)\n",
        "      return linear_output if not activation_fn else activation_fn(linear_output)\n",
        "    \n",
        "  def train(self, session, learning_rate, training_batches, batches_per_sample, save_model_as=None):\n",
        "    \"\"\"\n",
        "    Trains the model on the MNIST training dataset\n",
        "    \n",
        "    :param session: SEssion\n",
        "      Used to run training graph operation\n",
        "    :param learning_rate: float\n",
        "      Learning rate used during gradient descent.\n",
        "    :param training_batches: int\n",
        "      Number of batches to train.\n",
        "    :param batches_per_sample: int\n",
        "      How many batches to train before sampling the validation accuracy.\n",
        "    :param save_model_as: string or None (default None)\n",
        "      Name to use if you want to save the trained model.\n",
        "    \"\"\"\n",
        "    \n",
        "    # This placeholder will store the target labels for each mini batch\n",
        "    labels = tf.placeholder(tf.float32, [None, 10])\n",
        "    \n",
        "    # Define loass and optimizaer\n",
        "    cross_entropy = tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=self.output_layer))\n",
        "    \n",
        "    # Define operation for testing\n",
        "    correct_prediction = tf.equal(tf.argmax(self.output_layer, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    \n",
        "    if self.use_batch_norm:\n",
        "      with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
        "    else:\n",
        "      train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
        "    \n",
        "    # Train for the appropriate number of batches. (tqdm is only for a nice timing display)\n",
        "    for i in tqdm.tqdm(range(training_batches)):\n",
        "      # We use batches of 60 just because the original paper did. You can use any size batch you like\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(60)\n",
        "      session.run(train_step, feed_dict={self.input_layer: batch_xs,\n",
        "                                        labels: batch_ys,\n",
        "                                        self.is_training: True})\n",
        "      \n",
        "      # Periodically test accuracy against the 5k validation images and store it for plotting later.\n",
        "      if i % batches_per_sample == 0:\n",
        "        test_accuracy = session.run(accuracy, feed_dict={self.input_layer: mnist.validation.images,\n",
        "                                                        labels: mnist.validation.labels,\n",
        "                                                        self.is_training: False})\n",
        "        self.training_accuracies.append(test_accuracy)\n",
        "        \n",
        "    # After training, report accuracy against test data\n",
        "    test_accuracy = session.run(accuracy, feed_dict={self.input_layer: mnist.validation.images,\n",
        "                                                    labels: mnist.validation.labels,\n",
        "                                                    self.is_training: False})\n",
        "    print('{}: After training, fanal accuracy on validaion set = {}'.format(self.name, test_accuracy))\n",
        "    \n",
        "    # If you want to use this model later for inference instead of having to retrain it,\n",
        "    # just construct it with the same parameters and then pass this file to the 'test' function\n",
        "    if save_model_as:\n",
        "      tf.train.Saver().save(session, save_model_as)\n",
        "    \n",
        "  def test(self, session, test_training_accuracy=False, include_individual_predictions=False, restore_from=None):\n",
        "    \"\"\"\n",
        "    Trains a trained model on the MNIST testing dataset.\n",
        "    \n",
        "    :param session: Session\n",
        "      Used to run the testing graph operations.\n",
        "    :param test_training_accurcay: bool (default False)\n",
        "      If True, perform inference with batch normalization using batch mean and varicance;\n",
        "      if False, perform inference with batch nomalization using estimated population mean and variance.\n",
        "      Note: in real life, *always* perform inference using the population mean and variance\n",
        "        This parameter exists just to support demostrating what happens if you don't\n",
        "    :param include_individual_predictions: bool (default True)\n",
        "    :param restore_from: string or None (default None)\n",
        "      Name of a saved model if you want to test with previously saved weights.\n",
        "    \"\"\"\n",
        "    # This placeholder will store the true labels for each mini batch\n",
        "    labels = tf.placeholder(tf.float32, [None, 10])\n",
        "    \n",
        "    # Define operations for testing\n",
        "    correct_prediction = tf.equal(tf.argmax(self.output_layer, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    \n",
        "    # If proveded, restore from a previously saved model\n",
        "    if restore_from:\n",
        "      tf.train.Saver().restore(session, restore_from)\n",
        "      \n",
        "    # Test against all of the MNIST test data\n",
        "    test_accuracy = session.run(accuracy, feed_dict={self.input_layer: mnist.test.images,\n",
        "                                                    labels: mnist.test.labels,\n",
        "                                                    self.is_training: test_training_accuracy})\n",
        "    print('-'*75)\n",
        "    print('{}: Accuracy on full test set = {}'.format(self.name, test_accuracy))\n",
        "    \n",
        "    # If requested, perform tests predicting individual values rather than batches\n",
        "    if include_individual_predictions:\n",
        "      predictions = []\n",
        "      correct = 0\n",
        "      \n",
        "      # Do 200 predictions, 1 at a time\n",
        "      for i in range(200):\n",
        "        # This is a normal prediction using an individual test case. However, notice\n",
        "        # we pass 'test_training_accuracy' to 'feed_dict' as the value for 'self.is_training'.\n",
        "        # Remember that will tell it whether it should use the batch mean & variance or\n",
        "        # the populatio estimates that were calculated while training the model\n",
        "        pred, corr = session.run([tf.arg_max(self.output_layer, 1), accuracy],\n",
        "                                feed_dict={self.input_layer: [mnist.test.images[i]],\n",
        "                                          labels:[mnint.test.labels[i]],\n",
        "                                          self.is_traing: test_training_accuracy})\n",
        "        correst += corr\n",
        "        predictions.append(pred[0])\n",
        "      print('200 Predcitions:', predictions)\n",
        "      print('Accuracy on 200 samples:', correct/200)\n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkCoDaf1JqrE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization Demos"
      ]
    },
    {
      "metadata": {
        "id": "Lw6GENwgJywf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code to support testing\n",
        "The following two functions support the demos we run in the notebook.\n",
        "The first function, `plot_training_accuracies`, simply plots the values found in the `training_accuracies` lists of the NeuralNet objects passed to it. If you look at the `train` function in `NerualNet`, you'll see it that while it's training the network, it periodically measures validation accuracy and stores the results in that list. It does that just to support these plots.\n",
        "\n",
        "The second function, `train_and_test`, creates two neural nts - one with and one without batch normalization. It then trains them both and tests them, calling `plot_training_accuracies` to plot how their accuracies changed over the course tof training. The really important thing about this function is that it initializes the starting weights for the networks outside of the networks and then passes them in. This lets it train both networks from the exact same starting weights, which eliminates performance differences that might result from (un) lucky initial weights."
      ]
    },
    {
      "metadata": {
        "id": "f-_gi10IJYoD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Code to support testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjgoAmYnJYoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_training_accuracies(*args, **kwargs):\n",
        "  \"\"\"\n",
        "  Display a plot of the accuracies calculated during training to demonstrate how many iterations it took for the model(s) to converge.\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots()\n",
        "  batches_per_sample = kwargs['batches_per_sample']\n",
        "  \n",
        "  for nn in args:\n",
        "    ax.plot(range(0, len(nn.training_accuracies)*batches_per_sample, batches_per_sample),\n",
        "            nn.training_accuracies, label=nn.name)\n",
        "    ax.set_xlabel('Training steps')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title('Validation Accuracy During Training')\n",
        "    ax.legend(loc=4)\n",
        "    ax.set_ylim([0,1])\n",
        "    plt.yticks(np.arange(0, 1.0, 0.1))\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "def train_and_test(use_bad_weights, learning_rate, activation_fn, training_batches=50000, batches_per_sample=500):\n",
        "  \"\"\"\n",
        "  Creates two networks, one with and one without batch normalization, then trains them\n",
        "  with identical strating weights, layers, batches, etc. Finally tests and plots their accuracies.\n",
        "  \"\"\"\n",
        "  \n",
        "  if use_bad_weights:\n",
        "    weights = [np.random.normal(size=(784,100), scale=5.0).astype(np.float32),\n",
        "              np.random.normal(size=(100,100), scale=5.0).astype(np.float32),\n",
        "              np.random.normal(size=(100,100), scale=5.0).astype(np.float32),\n",
        "              np.random.normal(size=(100,10), scale=5.0).astype(np.float32)]\n",
        "  else:\n",
        "    weights = [np.random.normal(size=(784,100), scale=0.5).astype(np.float32), \n",
        "              np.random.normal(size=(100,100), scale=0.5).astype(np.float32),\n",
        "              np.random.normal(size=(100,100), scale=0.5).astype(np.float32),\n",
        "              np.random.normal(size=(100,10), scale=0.5).astype(np.float32)]\n",
        "  \n",
        "  # Just to make sure the TensorFlow's default graph i empty before we start another\n",
        "  # test, because we don't bother using different graphs or scoping and naming\n",
        "  # elements carefully in this sample code.\n",
        "  tf.reset_default_graph()\n",
        "  \n",
        "  # build two versions of same network, 1 without and 1 with batch normalization\n",
        "  nn = NeuralNet(weights, activation_fn, False)\n",
        "  bn = NeuralNet(weights, activation_fn, True)\n",
        "  \n",
        "  # train and test the two models\n",
        "  with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    \n",
        "    nn.train(sess, learning_rate, training_batches, batches_per_sample)\n",
        "    bn.train(sess, learning_rate, training_batches, batches_per_sample)\n",
        "    \n",
        "    nn.test(sess)\n",
        "    bn.test(sess)\n",
        "    \n",
        "  plot_training_accuracies(nn, bn, batches_per_sample=batches_per_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14FRqeetQ_49",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Comparisions between identical networks, with and without batch normalization\n",
        "The next series of cells train networks with various settings to show the differences with and without batch normalization. They are meant to clearly demonstrate the effects of batch normalization. We include a deeper discussion of batch normalization later in the notebook."
      ]
    },
    {
      "metadata": {
        "id": "467Kn7UuRVRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The following creates two networks using a ReLU activation function, a learning rate of 0.01, and reasonable starting weights"
      ]
    },
    {
      "metadata": {
        "id": "gaiSxEkYQ1Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "b962f1dc-f741-46fc-b4ee-50a9c1bb8ab2"
      },
      "cell_type": "code",
      "source": [
        "train_and_test(False, 0.01, tf.nn.relu)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [02:23<00:00, 347.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Without Batch Norm: After training, fanal accuracy on validaion set = 0.9423999786376953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [05:42<00:00, 146.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "With Batch Norm: After training, fanal accuracy on validaion set = 0.9520000219345093\n",
            "---------------------------------------------------------------------------\n",
            "Without Batch Norm: Accuracy on full test set = 0.9390000104904175\n",
            "---------------------------------------------------------------------------\n",
            "With Batch Norm: Accuracy on full test set = 0.9470999836921692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEVCAYAAADtmeJyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndIOXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe24bbc6b38>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkJekihnyklQxQ16SKvb/jAqkyH0UyUUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe2502a8320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2uK2wsRiRkDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}